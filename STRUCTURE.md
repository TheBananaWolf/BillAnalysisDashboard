# Project Structure

## Complete Bill Analysis System

```
BillAnalysis/
â”‚
â”œâ”€â”€ ğŸ³ Docker & Deployment
â”‚   â”œâ”€â”€ Dockerfile                 # Docker container configuration
â”‚   â”œâ”€â”€ docker-compose.yml         # Docker Compose setup
â”‚   â””â”€â”€ .env.example               # Environment variables template
â”‚
â”œâ”€â”€ ğŸš€ Quick Start Scripts
â”‚   â”œâ”€â”€ run.py                     # Python quick start script
â”‚   â””â”€â”€ run.sh                     # Bash quick start script
â”‚
â”œâ”€â”€ ğŸ“± Main Application
â”‚   â””â”€â”€ main.py                    # Streamlit web interface
â”‚
â”œâ”€â”€ ğŸ”§ Source Code Modules
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ __init__.py            # Package initialization
â”‚       â”œâ”€â”€ data_processor.py      # Data loading & preprocessing
â”‚       â”œâ”€â”€ analyzer.py            # Financial analysis engine
â”‚       â”œâ”€â”€ visualizer.py          # Charts & visualizations
â”‚       â”œâ”€â”€ insights_generator.py  # AI insights & recommendations
â”‚       â””â”€â”€ notion_scraper.py      # Notion web scraping
â”‚
â”œâ”€â”€ ğŸ’¾ Data Storage
â”‚   â”œâ”€â”€ data/                      # User data storage
â”‚   â””â”€â”€ exports/                   # Export outputs
â”‚
â”œâ”€â”€ ğŸ“‹ Configuration
â”‚   â”œâ”€â”€ requirements.txt           # Python dependencies
â”‚   â””â”€â”€ .env.example              # Environment configuration
â”‚
â””â”€â”€ ğŸ“š Documentation
    â”œâ”€â”€ README.md                  # Main documentation
    â””â”€â”€ STRUCTURE.md               # This file
```

## Key Features by File

### ğŸ“± **main.py** - Web Interface
- Streamlit-based dashboard
- Multi-page navigation
- Data upload interface
- Notion URL integration
- Interactive visualizations
- Export functionality

### ğŸ”§ **src/data_processor.py** - Data Processing
- File format support (CSV, Excel, JSON)
- Notion URL data extraction
- Data cleaning and validation
- Automatic categorization
- Sample data generation

### ğŸ“Š **src/analyzer.py** - Analysis Engine
- Monthly/yearly spending analysis
- Category breakdowns
- Trend detection
- Anomaly identification
- Growth rate calculations
- Financial health metrics

### ğŸ“ˆ **src/visualizer.py** - Visualization
- Interactive Plotly charts
- Monthly spending trends
- Category distributions
- Daily patterns
- Heatmaps and radar charts
- Timeline visualizations

### ğŸ§  **src/insights_generator.py** - AI Insights
- Spending pattern analysis
- Personalized recommendations
- Savings opportunity detection
- Budget suggestions
- Financial health assessment

### ğŸŒ **src/notion_scraper.py** - Web Scraping
- Selenium-based web scraping
- Notion page data extraction
- Multiple fallback methods
- Data format standardization
- Error handling and recovery

## Data Flow

```
1. Data Input
   â”œâ”€â”€ File Upload (CSV/Excel/JSON)
   â”œâ”€â”€ Notion URL Scraping
   â””â”€â”€ Sample Data Generation
   
2. Data Processing
   â”œâ”€â”€ Format Standardization
   â”œâ”€â”€ Data Cleaning
   â”œâ”€â”€ Validation
   â””â”€â”€ Categorization
   
3. Analysis
   â”œâ”€â”€ Statistical Analysis
   â”œâ”€â”€ Trend Detection
   â”œâ”€â”€ Pattern Recognition
   â””â”€â”€ Anomaly Detection
   
4. Visualization
   â”œâ”€â”€ Interactive Charts
   â”œâ”€â”€ Dashboards
   â”œâ”€â”€ Reports
   â””â”€â”€ Exports
   
5. Insights
   â”œâ”€â”€ AI-Generated Insights
   â”œâ”€â”€ Recommendations
   â”œâ”€â”€ Budget Suggestions
   â””â”€â”€ Health Metrics
```

## Technology Stack

- **Backend**: Python 3.11+
- **Web Framework**: Streamlit
- **Data Processing**: Pandas, NumPy
- **Visualization**: Plotly, Matplotlib, Seaborn
- **Web Scraping**: Selenium, BeautifulSoup, Requests
- **Containerization**: Docker, Docker Compose
- **Dependencies**: See requirements.txt

## Deployment Options

1. **Docker (Recommended)**
   ```bash
   docker-compose up --build
   ```

2. **Local Python**
   ```bash
   python run.py
   # or
   ./run.sh
   ```

3. **Manual Setup**
   ```bash
   pip install -r requirements.txt
   streamlit run main.py
   ```